# -*- coding:utf-8 -*-"""Created at 2:47 PM 12/4/2019This is to test with anomaly detection with sklearn algorithms.@author: guangqiang.lu"""from sklearn.datasets import load_irisfrom sklearn.svm import OneClassSVMfrom sklearn.ensemble import IsolationForestfrom sklearn.neighbors import LocalOutlierFactorimport matplotlib.pyplot as pltimport numpy as npimport warningswarnings.simplefilter('ignore')x, y = load_iris(return_X_y=True)# x = x[:, :2]   # for plot use casedef get_prediction_algorithms(al_name):    if al_name == 'one_class_svm':        clf = OneClassSVM()        clf.fit(x)        pred = clf.predict(x)    elif al_name == 'isolation_forest':        iso_forest = IsolationForest()        pred = iso_forest.fit_predict(x)    else:        lof = LocalOutlierFactor()        pred = lof.fit_predict(x)    return preddef plot_pred_abnomaly_class(preds, al_name_list=None):    fig = plt.figure(figsize=(16, 8))    for i in range(len(preds)):        pred = preds[i]        for cl in np.unique(pred):            ax = fig.add_subplot(1, len(preds), i + 1)            ax.scatter(x[pred == cl, 0], x[pred == cl, 1], label='normal' if cl == 1 else 'ab-nomal')            if al_name_list:                ax.set_title(al_name_list[i])                ax.set_xlabel('$x_1$')                ax.set_ylabel('$x_2$')    plt.legend()    plt.show()def abnormal_example_with_local_outer_factor():    """    this is just to test with local outlier factor algorithm    to do abnormal detection with sample data that we create.    Here is to scatter data point with whole data, and with    each data point probability as outliers with local outlier    factor algorithm prediction and plot these data points with    red circle to represent that probability.    Returns    -------    """    x_inlines = .3 * np.random.randn(100, 2)    x_inlines = np.r_[x_inlines + 2, x_inlines - 2]    # generate outlier points    x_outliers = np.random.uniform(low=-4, high=4, size=(20, 2))    x = np.r_[x_inlines, x_outliers]    n_outliers = len(x_outliers)    ground_truth = np.ones(len(x), dtype=int)    ground_truth[-n_outliers:] = -1    # as sklearn official website recommend that with neighbors with 20 will be ok    clf = LocalOutlierFactor(n_neighbors=20, contamination=.1)    pred = clf.fit_predict(x)    print("How many data with mis-pred: %d" % (pred == ground_truth).sum())    x_scores = clf.negative_outlier_factor_    radis = (x_scores.max() - x_scores) / (x_scores.max() - x_scores.min())    fig = plt.figure(figsize=(16, 8))    # plot data point    plt.scatter(x[:, 0], x[:, 1], color='k', s=3, label='data points')    # then plot the probability of outlier    plt.scatter(x[:, 0], x[:, 1], s=1000* radis, edgecolors='r', facecolors='none', label='outlier points')    plt.legend()    plt.show()class LocalOutlierFactorImplement(object):    """    The logic of local outlier factor is that first we should compute    the distance of each data point and compute the k nearest data points    distance and mean the distance, so that we could compute the average    distance of each data point the average distance between the circle    of that data point nearby, if this distance is smaller than another,    then we could conclude that this data point is more like to be inner    point, otherwise if we get a data point is really far away from nearby    data points, then we could look this data point as abnormal data points.    """    def __init__(self, n_neighbors=3):        self.n_neighbors = n_neighbors    @staticmethod    def _compute_distance(x, y):        # here is just (x - y)**2        return np.sqrt(np.sum((x - y) ** 2, axis=0))    def _compute_k_distance(self, data, k=None):        """        compute distance with k neighbors        Parameters        ----------        data : array like with (n, m)        k : how many neighbors to compute        Returns        -------        array of (n, k) with n samples and k distances        """        # for now I would use loop to compute each data point        distance_array = np.empty((len(data), len(data)), dtype=float)        for i in range(len(data)):            for j in range(len(data)):                distance_array[i, j] = self._compute_distance(data[i, :], data[j, :])        if k is None:            k = self.n_neighbors        k_distance = np.asarray([sorted(x)[:k] for x in distance_array])        return k_distance    def fit(self, data):        k_distance = self._compute_k_distance(data)        self.scores =  1.0 / k_distance.mean(axis=1)if __name__ == '__main__':    # al_name_list = ['one_class_svm', 'isolation_forest', 'local_outlier_factor']    # preds = [get_prediction_algorithms(al) for al in al_name_list]    #    # plot_pred_abnomaly_class(preds, al_name_list)    # abnormal_example_with_local_outer_factor()    lofi = LocalOutlierFactorImplement()    lofi.fit(x)    print(lofi.scores)