# -*- coding:utf-8 -*-"""Created at 4:42 PM 1/11/2020This is according to effective python with implementation with map-reduce functionality.@author: guangqiang.lu"""import osfrom threading import Threadimport tempfileimport shutiln_files = 8write_str = 'machine'tmp_path = tempfile.mkdtemp()# # first with parent class that we could inherent with data reading# class InputData(object):#     def read(self):#         raise NotImplementedError## # this class is used to read file with open function# class FileInputData(InputData):#     def __init__(self, path):#         super().__init__()#         self.path = path##     def read(self):#         return open(self.path).read()### # Then we could define our worker class# class Worker(object):#     def __init__(self, input_data):#         self.input_data = input_data#         self.result = None##     def map(self):#         raise NotImplementedError##     def reduce(self, other):#         raise NotImplementedError## # we could make our Line reader workers# class LineWorker(Worker):#     def map(self):#         data = self.input_data.read()#         self.result = data.count('1') if '1' in data else 0##     def reduce(self, other):#         # this means that we could use other workers result and sum into one#         self.result += other.result## # build a connect function to combine whole of them# def generate_inputs(data_dir):#     for name in os.listdir(data_dir):#         yield FileInputData(os.path.join(tmp_path, name))## # then we should create workers for this# def create_workers(input_list):#     workers = []#     for input_data in input_list:#         workers.append(LineWorker(input_data))#     return workers## # we should implement with different thread function that we could combine the result# def excute(workers):#     threads = [Thread(target=w.map) for w in workers]#     # start thread#     for thread in threads: thread.start()#     for thread in threads: thread.join()##     # get first worker and rest workers#     first, rest = workers[0], workers[1:]#     for worker in rest:#         first.reduce(worker)##     return first.result## # then we could implement with final map reduce function# def mapreduce(data_dir):#     inputs = generate_inputs(data_dir)#     workers = create_workers(inputs)#     return excute(workers)## # we should make a tempfile and write some data into it# def sample_data():#     for i in range(5):#         with open(os.path.join(tmp_path, 'file_%s.txt' % str(i)), 'w') as f:#             f.write("1" * (i + 1) * 10)## if __name__ == '__main__':#     sample_data()#     res = mapreduce(tmp_path)#     print("We get %d 1 string" % res)#     print("Whole finished, we should remove folder")#     shutil.rmtree(tmp_path)"""----in fact we could also make a more generate way to solve this problem"""# class GenerateInputData(object):#     def read(self):#         raise NotImplementedError##     @classmethod#     def generate_inputs(cls):#         raise NotImplementedError## class LineGnereateInputData(GenerateInputData):#     def __init__(self, path):#         super(LineGnereateInputData, self).__init__()#         self.path = path##     def read(self):#         return open(self.path).read()##     @classmethod#     def generate_inputs(cls):#         for file in os.listdir(tmp_path):#             yield cls(os.path.join(tmp_path, file))### class GeneralWorker(object):#     def __init__(self, input_data):#         self.input_data = input_data#         self.result = None##     def map(self):#         raise NotImplementedError##     def reduce(self, other):#         raise NotImplementedError##     @classmethod#     def create_workers(cls, input_class):#         # in fact we could just create the functionality in this function#         # so for sub-class should focus on the logic implement with map and reduce.#         workers = []#         for input_data in input_class.generate_inputs():#             # with cls, we could just instant object with current class without to instant object.#             workers.append(cls(input_data))##         return workers### class LineGenralWorker(GeneralWorker):#     def map(self):#         data = self.input_data.read()#         self.result = data.count(write_str)##     def reduce(self, other):#         self.result += other.result##     # @classmethod#     # def create_workers(cls, input_class):#     #     workers = []#     #     for input_data in input_class.generate_inputs():#     #         workers.append(cls(input_data))#     #     return workers## def execute(workers):#     threads = [Thread(target=w.map) for w in workers]#     # start thread#     for thread in threads: thread.start()#     for thread in threads: thread.join()##     # get first worker and rest workers#     first, rest = workers[0], workers[1:]#     for worker in rest:#         first.reduce(worker)##     return first.result## def mapreduce(worker_class, input_class):#     workers = worker_class.create_workers(input_class)#     return execute(workers)## def sample_data():#     for i in range(5):#         with open(os.path.join(tmp_path, 'file_%s.txt' % str(i)), 'w') as f:#             f.write(write_str * (i + 1) * 10)# if __name__ == '__main__':#     sample_data()#     res = mapreduce(LineGenralWorker, LineGnereateInputData)#     print("Get %d %s strings" % (res, write_str))#     shutil.rmtree(tmp_path)def sample_data():    for i in range(n_files):        with open(os.path.join(tmp_path, 'file_%s.txt' % (i)), 'w') as f:            f.write(write_str * (i + 1) * 10)class GeneralInput(object):    """    this should be a abstract class that we should first define what    function that we should implement, then for sub-class, we could    just implement with the logic that we could use for each class.    the reason why we should define this class with abstract class    is that for each subclass could have their own logic,    but with worker class, we all use Worker parent class to create    with as input_data object numbers worker, and with sub-class    could just focus on the implement with map and reduce function.    """    def read(self):        raise NotImplementedError    @classmethod    def generate_inputs(cls):        raise NotImplementedErrorclass LineGeneralInput(GeneralInput):    def __init__(self, path):        super(LineGeneralInput, self).__init__()        self.path = path    def read(self):        data = open(self.path).read()        return data    @classmethod    def generate_inputs(cls):        for f in os.listdir(tmp_path):            yield cls(os.path.join(tmp_path, f))class GeneralWorker(object):    """    This should implement with the logic to create with cls class that    could be used to create each class that we could use to create    as much workers as we want.    Also we don't need to create a function to create workers object,    so that we could just use the class function to use class functionality.    """    def __init__(self, input_data):        self.input_data = input_data        self.result = None    def map(self):        raise NotImplementedError    def reduce(self, other):        raise NotImplementedError    @classmethod    def create_workers(cls, input_class):        workers = []        for f in input_class.generate_inputs():            workers.append(cls(f))        return workersclass LineGeneralWorker(GeneralWorker):    def map(self):        data = self.input_data.read()        self.result = data.count(write_str)    def reduce(self, other):        self.result += other.resultdef execute(workers):    threads = [Thread(target=w.map) for w in workers]    for thread in threads: thread.start()    for thread in threads: thread.join()    first, rest = workers[0], workers[1:]    for worker in rest:        first.reduce(worker)    return first.resultdef map_reduce():    workers = LineGeneralWorker.create_workers(LineGeneralInput)    return execute(workers)if __name__ == '__main__':    sample_data()    res = map_reduce()    print("Get %d %s values" % (res, write_str))    shutil.rmtree(tmp_path)